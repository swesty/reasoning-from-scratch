# Chapter 7: Improving Policy Optimization in Reinforcement Learning

&nbsp;

In progress ...







<br>

---

**Note**: If you are not a `uv` user, replace `uv run ...py` with `python ...py` in the examples below.

---


&nbsp;

|      | Method                    | Step | Max tokens | Num rollouts | MATH-500 Acc | Avg # of tokens |
| ---- | ------------------------- | ---- | ---------- | ------------ | ------------ | --------------- |
| 1    | Base (chapter 3)          | -    |            |              | 15.2%        | 78.85           |
| 2    | Reasoning (chapter 3)     | -    |            |              | 48.2%        | 1369.79         |
| 3    | GRPO original             | 50   | 512        | 8            | 33.4%        | 910.33          |
| 4    | GRPO (Olmo 3 mod.)        | 50   | 512        | 8            | 46.4%        | 601.61          |
| 5    | GRPO (DeepSeek V3.2 mod.) | 50   | 512        | 8            | 44.2%        | 618.49          |

